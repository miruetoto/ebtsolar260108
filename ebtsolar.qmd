---
title: "Elastic-Band Transform–Integrated Spatio-Temporal Graph Neural Networks for Solar Radiation Forecasting"
subtitle: "다중척도워크샵2026"
author: "최규빈"
institute: "전북대학교 통계학과"
date: "2026-01-07"
bibliography: ref.bib
csl: apa.csl
format:
  revealjs:
    theme: custom.scss
    slide-number: true
    chalkboard: false
    preview-links: auto
    transition: none
    width: 1600
    height: 900
    smaller: true
    scrollable: true
    fig-format: png
    fig-dpi: 300
    auto-stretch: true
    html-math-method: mathjax
---

## Table of Contents

1. **Introduction**
   - Characteristics / Problem / Solution
   - STGNN and Adjacency Matrix Estimation

2. **Proposed Method**
   - Multiplicative Decomposition (EBT)
   - Overall Framework and Advantages

3. **Experiments**
   - Experimental Setup and Results
   - Typhoon Hinnamnor Period Analysis

4. **Discussions**
   - Key Contributions
   - Reviewer Questions

# Introduction

## Characteristics of Solar Irradiance Data

:::: {.columns}
::: {.column width="60%"}
![Figure: Solar irradiance time series observed in Seoul. Strong daily periodicity coexists with irregular fluctuations.](figs/fig1.png){width="100%"}
:::
::: {.column width="40%"}
**Simple data, but challenging to analyze**

**1. Strong periodicity**

- Clear daily periodic pattern (sunrise to sunset)

**2. Zero-Value Intervals at Night**

- Solar irradiance is structurally zero during nighttime
:::
::::

## Problem

**Traditional time series models are not applicable**

- Traditional models such as AR(Auto-Regressive) and ARMA(Auto-Regressive Moving Average) require stationarity assumptions, but the data violates these due to nighttime zero intervals

**Deep learning models are also difficult to apply**

- LSTM(Long Short-Term Memory), TCN(Temporal Convolutional Network), etc. have no assumption issues, but require excessive training time to accurately learn nighttime zeros

**What if we exclude nighttime zero intervals for prediction?**

- Sunrise/sunset times vary by season, making uniform exclusion like "7 PM to 6 AM" impossible
- Excluding zero-value intervals risks also excluding low irradiance during cloudy daytime periods

**What if we decompose and remove the periodic component?**

- Half-wave shape makes sinusoid-based decomposition difficult
- The periodicity is not "added" on top of the signal (additive), so STL(Seasonal-Trend decomposition using Loess), EMD(Empirical Mode Decomposition), Wavelet, etc. cannot cleanly separate it

## A Possible Approach (Previous Work)

> Rather than predicting the next time point from previous observations, it is more reasonable to **first predict whether the sun will be up at the next time point**, and then predict solar irradiance conditional on the sun being up. 

**Key Insight**

- Treat solar irradiance prediction as a **two-stage problem**:
  1. Is the sun up or not?
  2. If up, what is the irradiance level?

**Prior Research** [@lee2021short]

- Introduced a **latent variable** $Z_t \in \{0, 1\}$ to represent sun-up status
- Proposed a prediction model using the **EM(Expectation-Maximization) algorithm** to jointly estimate the latent state and irradiance

## This Study: Spatio-Temporal Extension

:::: {.columns}
::: {.column width="60%"}
![Figure: Solar irradiance across multiple regions in Korea. Geographically closer locations exhibit higher similarity.](figs/fig2.png){width="100%"}
:::
::: {.column width="40%"}
**From single time series to multiple regions**

- Previous work: prediction for a **single location**
- This study: **simultaneous prediction for 44 stations** across Korea

**Data**

- Hourly solar irradiance from 44 weather stations
- Approximately 107 days of observations

**Modeling as a Graph**

- $\mathcal{G}_t = (\mathcal{V}, \mathbf{A}, \{y_{v,t}\})$
- $\mathcal{V}$: set of 44 stations (nodes)
- $\mathbf{A}$: adjacency matrix representing connectivity between stations
- $y_{v,t}$: solar irradiance at station $v$ and time $t$
:::
::::

# Related Works

## Solar Irradiance Forecasting: Single-Site Models

**Deep learning approaches for individual locations**

- LSTM(Long Short-Term Memory) [@hochreiter1997lstm], CNN-LSTM [@agga2021short], TCN(Temporal Convolutional Network) [@bai2018tcn]
- Temporal Fusion Transformer [@lim2021temporal]: state-of-the-art in multi-horizon forecasting

**Limitation**

- Cannot explicitly model **spatial correlations** across multiple measurement stations
- Solar irradiance is affected by cloud movement, atmospheric circulation, and topography
- Single-site models miss these **spatial dependencies**

## Why STGNN is a Natural Choice

**STGNN(Spatio-Temporal Graph Neural Network)**

- Represent stations as **nodes**, learn **spatial** and **temporal** dynamics simultaneously
- Successful in traffic [@li2017diffusion; @yu2017spatio], time series [@wu2019graph; @wu2020connecting], network dynamics [@cui2020learning]

**STGNN for Solar/PV Forecasting**

- Spatiotemporal GNN(st-GNN) for PV performance prediction [@khodayar2021spatio]: 316 systems, outperforms temporal-only models

# Challenges in Graph Construction

## Challenges in Applying STGNN

**Key Issue**: STGNN cannot be directly applied to solar irradiance data

**Absence of Adjacency Matrix $\mathbf{A}$**

- STGNN typically **assumes** that node connectivity information $\mathbf{A}$ is **given**
- However, this is generally **not provided information**

<div style="width: fit-content; margin: auto;">

| Domain | Adjacency Matrix $\mathbf{A}$ |
|:---:|:---|
| Traffic Networks | Road connectivity is **clearly given** |
| Weather Observation Networks | Regional connectivity is **not given** |

</div>

**Therefore, $\mathbf{A}$ must be estimated**

## Estimating $\mathbf{A}$ Method 1: Distance-Based

:::: {.columns}
::: {.column width="60%"}
![Figure: Comparison of 대전–서산 (96.2 km) and 철원–인천 (94.9 km). Similar distance, but different pattern similarity.](figs/fig3.png){width="100%"}
:::
::: {.column width="40%"}
**Distance-Based Estimation**

- Assume nearby regions have similar solar irradiance 

**But this assumption often fails**

- Even if distance is close, **different terrain leads to different climate characteristics**

<div style="width: fit-content; margin: auto;">

| Region Pair | Distance | Pattern Similarity |
|:---:|:---:|:---|
| 대전-서산 | 96.2 km | **Low**  |
| 철원-인천 | 94.9 km | **High** |

</div>

Similar distance does not guarantee similar patterns
:::
::::

## Estimating $\mathbf{A}$ Method 2: Correlation-Based

:::: {.columns}
::: {.column width="50%"}
![Figure: Correlation matrix of solar irradiance among all stations. Overall correlations are very high.](figs/fig4.png){width="90%"}
:::
::: {.column width="50%"}
**Correlation-Based Estimation**

- Correlation matrix of solar irradiance among 44 stations

**Problem**

- Most pairs show **very high correlation**
- Even the **lowest correlation is 0.64** — unexpectedly high
- Much higher than intuitively expected
- Does not match actual climatic similarity between regions

:::
::::

## Visualization of Spurious Correlation

:::: {.columns}
::: {.column width="50%"}
![Figure: 서울–흑산도 (r=0.6422) vs 고창–영광 (r=0.9681). High correlation doesn't mean similar patterns.](figs/fig5.png){width="100%"}
:::
::: {.column width="50%"}

<div style="width: fit-content; margin: auto;">

| Region Pair | Correlation | Actual Pattern |
|:---:|:---:|:---|
| 고창–영광 | 0.9681 | High similarity |
| 서울–흑산도 | 0.6422 | **Nearly opposite patterns** |

</div>

**서울–흑산도**

- Patterns appear **nearly negatively correlated**
- Yet the correlation coefficient is **0.64 — very high**

**Problem**

- If we apply a model directly, 서울 prediction would consider 흑산도 with **weight 0.6**
- This might be useful for nighttime zeros, but **useless for daytime prediction**
:::
::::

# Proposed Method

## Proposed Method: Multiplicative Decomposition

**Our Goal: Decomposing Periodicity**

- Spurious correlation arises due to the **periodic component** (nighttime zeros). The correlation we intuitively expect reflects **similarity excluding periodicity**
- If we can **separate the periodic component** from the signal, the problem may be resolved

**Preliminary: Signal decomposition is not limited to additive models**

$$\cos(58\pi t) + \cos(62\pi t) = 2\cos(60\pi t) \cdot \cos(2\pi t)$$

- **Left-hand side**: Additive model (sum of two frequency components)
- **Right-hand side**: Multiplicative model (carrier × envelope)

**Decompose solar irradiance multiplicatively**

$$y_{v,t} = y_{v,t}^U \times y_{v,t}^P$$

<div style="width: fit-content; margin: auto;">

| Component | Meaning | Characteristics |
|:---:|:---|:---|
| $y_{v,t}^U$ | **Climate component** — reflects weather conditions | Upper envelope |
| $y_{v,t}^P$ | **Periodic component** — sunrise/sunset pattern | Normalized daily cycle ($\in [0,1]$) |

</div>

## EBT Decomposition Process {.scrollable}

::: {style="overflow-y: auto; max-height: 800px;"}
![Figure: EBT decomposition process. Left: Elastic bands with τ=24 and upper envelope extraction. Right: Amplitude modulation $y^U$ (top) and periodic component $y^P$ (bottom).](figs/sec32_fig1.png){width="100%"}
:::

**Solved via EBT(Elastic-Band Transform)** [@choi2023elastic; @choi2024decomposition]

- **Left**: Construct elastic bands with $\tau=24$ hourly intervals → extract upper envelope
- **Top right**: Climate component $y_{v,t}^U$ — maximum achievable irradiance given weather
- **Bottom right**: Periodic component $y_{v,t}^P$ — normalized sunrise/sunset pattern

## Correlation Structure After Decomposition {.scrollable}

::: {style="overflow-y: auto; max-height: 800px;"}
![Figure: Correlation structure comparison after decomposition. $y^P$: Dense (nationwide similarity). $y^U$: Sparse (climatologically similar regions only).](figs/corr_grid_plot_v3.png){width="100%"}
:::

**Decomposition works well!**

- **Periodic component** $y^P$: Correlation matrix becomes **denser** — nearly identical nationwide ($r \approx 1$)
- **Climate component** $y^U$: Correlation matrix becomes **sparser** — high correlation only among climatically similar regions

## Overall Framework {.scrollable}

::: {style="overflow-y: auto; max-height: 800px;"}
![Figure: Overall framework. Decompose with EBT, apply STGNN to each component separately, then recombine predictions.](pipeline.png){width="100%"}
:::

**Apply STGNN to each decomposed component, then recombine**

$$\hat{y}_{v,t+h} = \hat{y}_{v,t+h}^U \times \hat{y}_{v,t+h}^P$$

## Advantages of the Proposed Method

**1. Reasonable Graph Connectivity**

<div style="width: fit-content; margin: auto;">

| Component | Graph | Reason |
|:---:|:---:|:---|
| Periodic $y^P$ | **Dense** | Sunrise/sunset pattern similar across all regions → consider all stations |
| Climate $y^U$ | **Sparse** | Only climatically similar regions matter → fewer connections reasonable |

</div>

**2. Easier Prediction**

- **Periodic component**: Highly regular → easy for the model to learn
- **Climate component**: Removing periodicity simplifies the signal → easier to predict

**3. Flexible and Easy Lag/Filter Selection**

<div style="width: fit-content; margin: auto;">

| Component | Optimal Lag | Number of Filters |
|:---:|:---:|:---|
| Periodic $y^P$ | **lag = 24** (full day) | More filters needed |
| Climate $y^U$ | **lag = 4** (short-term sufficient) | Fewer filters sufficient |

</div>

# Experiments

## STGNN Architectures Used in Experiments

<div style="width: fit-content; margin: auto;">

| Model | Temporal | GNN Layer | Characteristics |
|:---:|:---:|:---:|:---|
| **GConvGRU** | GRU | Chebyshev | Spectral graph convolution |
| **GConvLSTM** | LSTM | Chebyshev | Includes peephole connections |
| **T-GCN** | GRU | GCN | Lightweight first-order approximation |
| **DCRNN** | GRU | DiffConv | Bidirectional diffusion convolution |

</div>

**References**: @seo2018structured, @zhao2019t, @li2017diffusion, @rozemberczki2021pytorch

## Experimental Setup

- **Data**: 44 weather stations in Korea, approximately 107 days of hourly observations
- **Data split**: Training 80% / Test 20%
- **Test period event**: **Typhoon Hinnamnor** in early September 2022 [@digital_typhoon]

**Comparison of three prediction strategies**

<div style="width: fit-content; margin: auto;">

| Strategy | Description |
|:---:|:---|
| **Classic** | Direct prediction of raw time series with a single STGNN |
| **Proposed $(L,L)$** | Apply same lag to both components after EBT decomposition |
| **Proposed $(4,L)$** | Climate component lag=4, periodic component lag=$L$ |

</div>

## Experimental Results: GConvGRU (MSE) {.scrollable}

<div style="width: fit-content; margin: auto;">

| Lag | F | Classic | Proposed (L,L) | Proposed (4,L) |
|:---:|:---:|:---:|:---:|:---:|
| 8 | 8 | 0.0535<sub>±0.0011</sub> | 0.0430<sub>±0.0021</sub> | [**0.0419**<sub>±0.0007</sub>]{style="color: red;"} |
| 8 | 16 | 0.0537<sub>±0.0012</sub> | 0.0413<sub>±0.0008</sub> | [**0.0408**<sub>±0.0010</sub>]{style="color: red;"} |
| 8 | 24 | 0.0535<sub>±0.0011</sub> | 0.0416<sub>±0.0010</sub> | [**0.0404**<sub>±0.0007</sub>]{style="color: red;"} |
| 8 | 32 | 0.0541<sub>±0.0005</sub> | 0.0408<sub>±0.0012</sub> | [**0.0400**<sub>±0.0003</sub>]{style="color: red;"} |
| 12 | 8 | 0.0534<sub>±0.0012</sub> | 0.0438<sub>±0.0013</sub> | [**0.0426**<sub>±0.0006</sub>]{style="color: red;"} |
| 12 | 16 | 0.0544<sub>±0.0008</sub> | 0.0426<sub>±0.0010</sub> | [**0.0416**<sub>±0.0004</sub>]{style="color: red;"} |
| 12 | 24 | 0.0548<sub>±0.0008</sub> | 0.0423<sub>±0.0017</sub> | [**0.0415**<sub>±0.0004</sub>]{style="color: red;"} |
| 12 | 32 | 0.0549<sub>±0.0007</sub> | 0.0427<sub>±0.0017</sub> | [**0.0411**<sub>±0.0004</sub>]{style="color: red;"} |
| 24 | 8 | 0.0657<sub>±0.0023</sub> | 0.0512<sub>±0.0016</sub> | [**0.0461**<sub>±0.0013</sub>]{style="color: red;"} |
| 24 | 16 | 0.0662<sub>±0.0018</sub> | 0.0499<sub>±0.0029</sub> | [**0.0471**<sub>±0.0007</sub>]{style="color: red;"} |
| 24 | 24 | 0.0675<sub>±0.0024</sub> | 0.0507<sub>±0.0026</sub> | [**0.0470**<sub>±0.0008</sub>]{style="color: red;"} |
| 24 | 32 | 0.0677<sub>±0.0010</sub> | 0.0503<sub>±0.0013</sub> | [**0.0472**<sub>±0.0007</sub>]{style="color: red;"} |

</div>

→ **Applying STGNN after EBT decomposition yields better performance overall** (approximately 20-30% MSE reduction)

## Typhoon Hinnamnor Period {.scrollable}

::: {style="overflow-y: auto; max-height: 800px;"}
![Figure: Typhoon Hinnamnor period analysis. Top 9 regions with highest MSE reduction along the typhoon path.](figs/251121_top9_typhoon_map_timeseries_geojson.png){width="100%"}
:::

**This improvement is especially pronounced during the Hinnamnor period**

## Regional Performance Improvement During Typhoon Period

<div style="width: fit-content; margin: auto;">

| # | Region | Classic | Proposed | MSE Reduction |
|:---:|:---|:---:|:---:|:---:|
| 1 | 경주 | 0.0791 | 0.0436 | [**44.9%**]{style="color: red;"} |
| 2 | 함양 | 0.0596 | 0.0343 | [**42.5%**]{style="color: red;"} |
| 3 | 창원 | 0.0644 | 0.0375 | [**41.8%**]{style="color: red;"} |
| 4 | 의령 | 0.0561 | 0.0353 | **37.1%** |
| 5 | 부산 | 0.0753 | 0.0493 | **34.5%** |
| 6 | 고산 | 0.0388 | 0.0257 | **33.8%** |
| 7 | 양산 | 0.0746 | 0.0497 | **33.4%** |
| 8 | 김해 | 0.0725 | 0.0485 | **33.1%** |
| 9 | 청송 | 0.0539 | 0.0363 | **32.6%** |

</div>

→ **32-45% MSE reduction** along the typhoon path (southeastern Korean Peninsula)

# Discussions 

## Key Contributions

**1. Multiplicative Decomposition Framework**

- Introduced **$y = y^U \times y^P$ decomposition model** for solar irradiance
- **Resolved spurious correlation problem** caused by periodicity

**2. Asymmetric Component Modeling**

- **Independent graph structures and hyperparameters** tailored to each component
- Climate: lag=4, sparse / Periodic: lag=24, dense

**3. Robustness Under Extreme Weather**

- **32-45% MSE reduction** during Typhoon Hinnamnor period

## Reviewer Question 1: Why Not Other Decomposition Methods?

> *"Comparison with alternative decomposition techniques such as STL, EMD, and Wavelet?"*

<div style="width: fit-content; margin: auto;">

| Method | Decomposition Type | Result |
|:---:|:---:|:---|
| STL | Additive | Daily component remains in residual |
| EMD | Additive | Periodic component not isolated to specific IMF |
| Wavelet | Additive | Periodic energy dispersed across multiple levels |
| **EBT** | **Multiplicative** | **Clean two-component separation** |

</div>

→ **Additive methods fail to cleanly separate components. Only EBT achieves clean separation**

## Decomposition Comparison: Raw Scale {.scrollable}

::: {style="overflow-y: auto; max-height: 800px;"}
![Figure: Decomposition comparison on raw-scale. EBT (top) vs STL, EMD, Wavelet (additive methods).](figs/A1_fig1.png){width="100%"}
:::

## Decomposition Comparison: Log Scale {.scrollable}

::: {style="overflow-y: auto; max-height: 800px;"}
![Figure: Decomposition comparison on log-scale. Multiplicative framing via log-transform still fails for STL, EMD, Wavelet.](figs/A1_fig2.png){width="100%"}
:::

## Reviewer Question 2: What About Non-STGNN Deep Learning?

> *"Comparison with LSTM, CNN-LSTM, TCN, etc.?"*

**Baseline models**: TCN, LSTM, CNN-LSTM [@bai2018tcn; @hochreiter1997lstm; @agga2021short]

<div style="width: fit-content; margin: auto;">

| Model | MSE | Setting |
|:---:|:---:|:---:|
| TCN | 0.0601<sub>±.0012</sub> | L=24 |
| LSTM | 0.0841<sub>±.0023</sub> | L=8 |
| CNN-LSTM | 0.0975<sub>±.0037</sub> | L=8 |
| **Proposed (EBT+STGNN)** | [**0.0400**<sub>±.0003</sub>]{style="color: red;"} | L=8 |

</div>

→ **STGNN leveraging spatial information significantly outperforms temporal-only models** (33% improvement over TCN)

## Thank You

**Paper Information**

**"Spatio-Temporal Graph Neural Networks with Elastic-Band Transform for Solar Radiation Prediction"**

**Author**: Guebin Choi

*CMES-Computer Modeling in Engineering & Sciences*, 2025

**Contact**: guebin.choi@jbnu.ac.kr

## References
