---
title: "Elastic-Band Transform–Integrated Spatio-Temporal Graph Neural Networks for Solar Radiation Forecasting"
subtitle: "다중척도워크샵2026"
author: "최규빈"
institute: "전북대학교 통계학과"
date: "2026-01-07"
bibliography: ref.bib
csl: apa.csl
format:
  revealjs:
    theme: custom.scss
    slide-number: true
    chalkboard: false
    preview-links: auto
    transition: none
    width: 1600
    height: 900
    smaller: true
    scrollable: true
    fig-format: png
    fig-dpi: 300
    auto-stretch: true
    html-math-method: mathjax
---

## Table of Contents

1. **Introduction**
   - Characteristics / Problem / Solution
   - STGNN and Adjacency Matrix Estimation

2. **Proposed Method**
   - Multiplicative Decomposition (EBT)
   - Overall Framework and Advantages

3. **Experiments**
   - Experimental Setup and Results
   - Typhoon Hinnamnor Period Analysis

4. **Discussions**
   - Key Contributions
   - Reviewer Questions

# Introduction

## Characteristics of Solar Irradiance Data

:::: {.columns}
::: {.column width="60%"}
![Figure: Solar irradiance time series observed in Seoul. Strong daily periodicity coexists with irregular fluctuations.](figs/fig1.png){width="100%"}
:::
::: {.column width="40%"}
**Simple data, but challenging to analyze**

**1. Strong periodicity**

- Clear daily periodic pattern (sunrise to sunset)

**2. Zero-Value Intervals at Night**

- Solar irradiance is structurally zero during nighttime
:::
::::

## Problem

**Traditional time series models are not applicable**

- Traditional models such as AR(Auto-Regressive) and ARMA(Auto-Regressive Moving Average) require stationarity assumptions, but the data violates these due to nighttime zero intervals

**Deep learning models are also difficult to apply**

- LSTM(Long Short-Term Memory), TCN(Temporal Convolutional Network), etc. have no assumption issues, but require excessive training time to accurately learn nighttime zeros

**What if we exclude nighttime zero intervals for prediction?**

- Sunrise/sunset times vary by season, making uniform exclusion like "7 PM to 6 AM" impossible
- Excluding zero-value intervals risks also excluding low irradiance during cloudy daytime periods

**What if we decompose and remove the periodic component?**

- Half-wave shape makes sinusoid-based decomposition difficult
- The periodicity is not "added" on top of the signal (additive), so STL(Seasonal-Trend decomposition using Loess), EMD(Empirical Mode Decomposition), Wavelet, etc. cannot cleanly separate it

## A Possible Approach (Previous Work)

> Rather than predicting the next time point from previous observations, it is more reasonable to **first predict whether the sun will be up at the next time point**, and then predict solar irradiance conditional on the sun being up. 

**Key Insight**

- Treat solar irradiance prediction as a **two-stage problem**:
  1. Is the sun up or not?
  2. If up, what is the irradiance level?

**Prior Research** [@lee2021short]

- Introduced a **latent variable** $Z_t \in \{0, 1\}$ to represent sun-up status
- Proposed a prediction model using the **EM(Expectation-Maximization) algorithm** to jointly estimate the latent state and irradiance

## This Study: Spatio-Temporal Extension

:::: {.columns}
::: {.column width="60%"}
![Figure: Solar irradiance across multiple regions in Korea. Geographically closer locations exhibit higher similarity.](figs/fig2.png){width="100%"}
:::
::: {.column width="40%"}
**From single time series to multiple regions**

- Previous work: prediction for a **single location**
- This study: **simultaneous prediction for 44 stations** across Korea

**Data**

- Hourly solar irradiance from 44 weather stations
- Approximately 107 days of observations

**Modeling as a Graph**

- $\mathcal{G}_t = (\mathcal{V}, \mathbf{A}, \{y_{v,t}\})$
- $\mathcal{V}$: set of 44 stations (nodes)
- $\mathbf{A}$: adjacency matrix representing connectivity between stations
- $y_{v,t}$: solar irradiance at station $v$ and time $t$
:::
::::

# Related Works

## Solar Irradiance Forecasting: Single-Site Models

**Deep learning approaches for individual locations**

- LSTM(Long Short-Term Memory) [@hochreiter1997lstm], CNN-LSTM [@agga2021short], TCN(Temporal Convolutional Network) [@bai2018tcn]
- Temporal Fusion Transformer [@lim2021temporal]: state-of-the-art in multi-horizon forecasting

**Limitation**

- Cannot explicitly model **spatial correlations** across multiple measurement stations
- Solar irradiance is affected by cloud movement, atmospheric circulation, and topography
- Single-site models miss these **spatial dependencies**

## Why STGNN is a Natural Choice

**STGNN(Spatio-Temporal Graph Neural Network)**

- Represent stations as **nodes**, learn **spatial** and **temporal** dynamics simultaneously
- Successful in traffic [@li2017diffusion; @yu2017spatio], time series [@wu2019graph; @wu2020connecting], network dynamics [@cui2020learning]

**STGNN for Solar/PV Forecasting**

- Spatiotemporal GNN(st-GNN) for PV performance prediction [@khodayar2021spatio]: 316 systems, outperforms temporal-only models

# Challenges in Graph Construction

## Challenges in Applying STGNN

**Key Issue**: STGNN cannot be directly applied to solar irradiance data

**Absence of Adjacency Matrix $\mathbf{A}$**

- STGNN typically **assumes** that node connectivity information $\mathbf{A}$ is **given**
- However, this is generally **not provided information**

<div style="width: fit-content; margin: auto;">

| Domain | Adjacency Matrix $\mathbf{A}$ |
|:---:|:---|
| Traffic Networks | Road connectivity is **clearly given** |
| Weather Observation Networks | Regional connectivity is **not given** |

</div>

**Therefore, $\mathbf{A}$ must be estimated**

## Estimating $\mathbf{A}$ Method 1: Distance-Based

:::: {.columns}
::: {.column width="60%"}
![Figure: Comparison of 대전–서산 (96.2 km) and 철원–인천 (94.9 km). Similar distance, but different pattern similarity.](figs/fig3.png){width="100%"}
:::
::: {.column width="40%"}
**Distance-Based Estimation**

- Assume nearby regions have similar solar irradiance 

**But this assumption often fails**

- Even if distance is close, **different terrain leads to different climate characteristics**

<div style="width: fit-content; margin: auto;">

| Region Pair | Distance | Pattern Similarity |
|:---:|:---:|:---|
| 대전-서산 | 96.2 km | **Low**  |
| 철원-인천 | 94.9 km | **High** |

</div>

Similar distance does not guarantee similar patterns
:::
::::

## Estimating $\mathbf{A}$ Method 2: Correlation-Based

:::: {.columns}
::: {.column width="50%"}
![Figure: Correlation matrix of solar irradiance among all stations. Overall correlations are very high.](figs/fig4.png){width="90%"}
:::
::: {.column width="50%"}
**Correlation-Based Estimation**

- Correlation matrix of solar irradiance among 44 stations

**Problem**

- Most pairs show **very high correlation**
- Even the **lowest correlation is 0.64** — unexpectedly high
- Much higher than intuitively expected
- Does not match actual climatic similarity between regions

:::
::::

## Visualization of Spurious Correlation

:::: {.columns}
::: {.column width="50%"}
![Figure: 서울–흑산도 (r=0.6422) vs 고창–영광 (r=0.9681). High correlation doesn't mean similar patterns.](figs/fig5.png){width="100%"}
:::
::: {.column width="50%"}

<div style="width: fit-content; margin: auto;">

| Region Pair | Correlation | Actual Pattern |
|:---:|:---:|:---|
| 고창–영광 | 0.9681 | High similarity |
| 서울–흑산도 | 0.6422 | **Nearly opposite patterns** |

</div>

**서울–흑산도**

- Patterns appear **nearly negatively correlated**
- Yet the correlation coefficient is **0.64 — very high**

**Problem**

- If we apply a model directly, 서울 prediction would consider 흑산도 with **weight 0.6**
- This might be useful for nighttime zeros, but **useless for daytime prediction**
:::
::::

# Proposed Method

## Proposed Method: Multiplicative Decomposition

**Our Goal: Decomposing Periodicity**

- Spurious correlation arises due to the **periodic component** (nighttime zeros). The correlation we intuitively expect reflects **similarity excluding periodicity**
- If we can **separate the periodic component** from the signal, the problem may be resolved

**Preliminary: Signal decomposition is not limited to additive models**

$$\cos(58\pi t) + \cos(62\pi t) = 2\cos(60\pi t) \cdot \cos(2\pi t)$$

- **Left-hand side**: Additive model (sum of two frequency components)
- **Right-hand side**: Multiplicative model (carrier × envelope)

**Decompose solar irradiance multiplicatively**

$$y_{v,t} = y_{v,t}^U \times y_{v,t}^P$$

- $y_{v,t}^U$: **Climate component** — reflects weather conditions (upper envelope)
- $y_{v,t}^P$: **Periodic component** — sunrise/sunset pattern (normalized daily cycle, $\in [0,1]$)

## EBT Decomposition Process

![Figure: EBT decomposition process. Left: Elastic bands with τ=24 and upper envelope extraction. Right: Amplitude modulation $y^U$ (top) and periodic component $y^P$ (bottom).](figs/sec32_fig1.png){width="100%"}

**Solved via EBT(Elastic-Band Transform)** [@choi2023elastic; @choi2024decomposition]

- **Left**: Construct elastic bands with $\tau=24$ hourly intervals → extract upper envelope
- **Top right**: Climate component $y_{v,t}^U$ — maximum achievable irradiance given weather
- **Bottom right**: Periodic component $y_{v,t}^P$ — normalized sunrise/sunset pattern

## Correlation Structure After Decomposition

![Figure: Correlation structure comparison after decomposition. $y^P$: Dense (nationwide similarity). $y^U$: Sparse (climatologically similar regions only).](figs/corr_grid_plot_v3.png){width="100%"}

**Decomposition works well!**

- **Periodic component** $y^P$: Correlation matrix becomes **denser** — nearly identical nationwide ($r \approx 1$)
- **Climate component** $y^U$: Correlation matrix becomes **sparser** — high correlation only among climatically similar regions

## Overall Framework

![Figure: Overall framework. Decompose with EBT, apply STGNN to each component separately, then recombine predictions.](pipeline.png){width="100%"}

**Apply STGNN to each decomposed component, then recombine**

$$\hat{y}_{v,t+h} = \hat{y}_{v,t+h}^U \times \hat{y}_{v,t+h}^P$$

## Advantages of the Proposed Method

**1. Reasonable Graph Connectivity**

- **Periodic $y^P$** → **Dense graph**: Sunrise/sunset pattern similar across all regions
- **Climate $y^U$** → **Sparse graph**: Only climatically similar regions matter

**2. Easier Prediction**

- **Periodic component**: Highly regular → easy for the model to learn
- **Climate component**: Removing periodicity simplifies the signal → easier to predict

**3. Component-Specific Hyperparameter Optimization**

<div style="width: fit-content; margin: auto;">

| Component | Optimal Lag | Number of Filters |
|:---:|:---:|:---|
| Periodic $y^P$ | **lag = 24** (full day) | More filters needed |
| Climate $y^U$ | **lag = 4** (short-term sufficient) | Fewer filters sufficient |

</div>

# Experiments

## STGNN Architectures Used in Experiments

**Core idea**: Replace standard matrix multiplication with graph convolution

$$\mathbf{h}_t = \sigma\left( \mathbf{W} \cdot \text{GraphConv}(\mathbf{X}_t, \mathbf{A}) + \mathbf{U} \cdot \mathbf{h}_{t-1} \right)$$

- $\mathbf{X}_t \in \mathbb{R}^{N \times F}$: input features at time $t$ ($N$: nodes, $F$: features)
- $\mathbf{A} \in \mathbb{R}^{N \times N}$: adjacency matrix, $\mathbf{h}_t$: hidden state
- $\mathbf{W}, \mathbf{U}$: learnable weight matrices, $\sigma$: activation function

## STGNN Architectures Used in Experiment

**Spectral Convolution** (GConvGRU/GConvLSTM, T-GCN):

$$\mathbf{X} \star_{\mathcal{G}} \mathbf{g} = \mathbf{U} \mathbf{g}_\theta \mathbf{U}^\top \mathbf{X} \approx \sum_{k=0}^{K-1} \theta_k T_k(\tilde{\mathbf{L}}) \mathbf{X}$$

- $\mathbf{L} = \mathbf{U} \mathbf{\Lambda} \mathbf{U}^\top$: eigen-decomposition of graph Laplacian
- $T_k$: Chebyshev polynomial of order $k$, $K$: polynomial order

**Diffusion Convolution** (DCRNN):

$$\mathbf{X} \star_{\mathcal{G}} \mathbf{g} = \sum_{j=0}^{J-1} \left( \theta_j \mathbf{P}^j + \theta_j' (\mathbf{P}^\top)^j \right) \mathbf{X}$$

- $\mathbf{P} = \mathbf{D}^{-1}\mathbf{A}$: random walk transition matrix ($\mathbf{A}$: adjacency, $\mathbf{D}$: degree)
- $J$: diffusion steps (hops)

## STGNN Architectures Used in Experiment

<div style="width: 70%; margin: auto;">

| Model | Temporal | GNN Layer | Order |
|:---:|:---:|:---:|:---:|
| **GConvGRU** | GRU | Chebyshev | $K \geq 2$ |
| **GConvLSTM** | LSTM | Chebyshev | $K \geq 2$ |
| **T-GCN** | GRU | GCN | $K = 1$ |
| **DCRNN** | GRU | DiffConv | $J \geq 2$ |

</div>

**References**: @seo2018structured, @zhao2019t, @li2017diffusion, @rozemberczki2021pytorch

## Experimental Setup

- **Data**: 44 weather stations in Korea, approximately 107 days of hourly observations
- **Data split**: Training 80% / Test 20%
- **Test period event**: **Typhoon Hinnamnor** in early September 2022 [@digital_typhoon]

**Comparison of three prediction strategies**

<div style="width: fit-content; margin: auto;">

| Strategy | Description |
|:---:|:---|
| **Classic** | Direct prediction of raw time series with a single STGNN |
| **Proposed $(L,L)$** | Apply same lag to both components after EBT decomposition |
| **Proposed $(4,L)$** | Climate component lag=4, periodic component lag=$L$ |

</div>

## Experimental Results (MSE)

::: {.panel-tabset}

### GConvGRU

| Lag | F | Classic | Proposed (L,L) | Proposed (4,L) |
|:---:|:---:|:---:|:---:|:---:|
| 8 | 8 | 0.0535<sub>±0.0011</sub> | 0.0430<sub>±0.0021</sub> | [**0.0419**<sub>±0.0007</sub>]{style="color: red;"} |
| 8 | 16 | 0.0537<sub>±0.0012</sub> | 0.0413<sub>±0.0008</sub> | [**0.0408**<sub>±0.0010</sub>]{style="color: red;"} |
| 8 | 24 | 0.0535<sub>±0.0011</sub> | 0.0416<sub>±0.0010</sub> | [**0.0404**<sub>±0.0007</sub>]{style="color: red;"} |
| 8 | 32 | 0.0541<sub>±0.0005</sub> | 0.0408<sub>±0.0012</sub> | [**0.0400**<sub>±0.0003</sub>]{style="color: red;"} |
| 12 | 8 | 0.0534<sub>±0.0012</sub> | 0.0438<sub>±0.0013</sub> | [**0.0426**<sub>±0.0006</sub>]{style="color: red;"} |
| 12 | 16 | 0.0544<sub>±0.0008</sub> | 0.0426<sub>±0.0010</sub> | [**0.0416**<sub>±0.0004</sub>]{style="color: red;"} |
| 12 | 24 | 0.0548<sub>±0.0008</sub> | 0.0423<sub>±0.0017</sub> | [**0.0415**<sub>±0.0004</sub>]{style="color: red;"} |
| 12 | 32 | 0.0549<sub>±0.0007</sub> | 0.0427<sub>±0.0017</sub> | [**0.0411**<sub>±0.0004</sub>]{style="color: red;"} |
| 24 | 8 | 0.0657<sub>±0.0023</sub> | 0.0512<sub>±0.0016</sub> | [**0.0461**<sub>±0.0013</sub>]{style="color: red;"} |
| 24 | 16 | 0.0662<sub>±0.0018</sub> | 0.0499<sub>±0.0029</sub> | [**0.0471**<sub>±0.0007</sub>]{style="color: red;"} |
| 24 | 24 | 0.0675<sub>±0.0024</sub> | 0.0507<sub>±0.0026</sub> | [**0.0470**<sub>±0.0008</sub>]{style="color: red;"} |
| 24 | 32 | 0.0677<sub>±0.0010</sub> | 0.0503<sub>±0.0013</sub> | [**0.0472**<sub>±0.0007</sub>]{style="color: red;"} |

### GConvLSTM

| Lag | F | Classic | Proposed (L,L) | Proposed (4,L) |
|:---:|:---:|:---:|:---:|:---:|
| 8 | 8 | 0.0518<sub>±0.0006</sub> | 0.0601<sub>±0.0551</sub> | [**0.0416**<sub>±0.0006</sub>]{style="color: red;"} |
| 8 | 16 | 0.0518<sub>±0.0007</sub> | 0.0418<sub>±0.0005</sub> | [**0.0408**<sub>±0.0006</sub>]{style="color: red;"} |
| 8 | 24 | 0.0519<sub>±0.0004</sub> | 0.0416<sub>±0.0007</sub> | [**0.0405**<sub>±0.0005</sub>]{style="color: red;"} |
| 8 | 32 | 0.0525<sub>±0.0004</sub> | 0.0419<sub>±0.0010</sub> | [**0.0402**<sub>±0.0004</sub>]{style="color: red;"} |
| 12 | 8 | 0.0524<sub>±0.0007</sub> | 0.0437<sub>±0.0010</sub> | [**0.0419**<sub>±0.0006</sub>]{style="color: red;"} |
| 12 | 16 | 0.0530<sub>±0.0008</sub> | 0.0433<sub>±0.0013</sub> | [**0.0419**<sub>±0.0004</sub>]{style="color: red;"} |
| 12 | 24 | 0.0534<sub>±0.0005</sub> | 0.0427<sub>±0.0010</sub> | [**0.0418**<sub>±0.0006</sub>]{style="color: red;"} |
| 12 | 32 | 0.0534<sub>±0.0005</sub> | 0.0425<sub>±0.0009</sub> | [**0.0419**<sub>±0.0005</sub>]{style="color: red;"} |
| 24 | 8 | 0.0618<sub>±0.0019</sub> | 0.0487<sub>±0.0027</sub> | [**0.0460**<sub>±0.0009</sub>]{style="color: red;"} |
| 24 | 16 | 0.0626<sub>±0.0013</sub> | 0.0498<sub>±0.0028</sub> | [**0.0461**<sub>±0.0007</sub>]{style="color: red;"} |
| 24 | 24 | 0.0641<sub>±0.0016</sub> | 0.0468<sub>±0.0017</sub> | [**0.0466**<sub>±0.0007</sub>]{style="color: red;"} |
| 24 | 32 | 0.0644<sub>±0.0013</sub> | 0.0486<sub>±0.0030</sub> | [**0.0463**<sub>±0.0008</sub>]{style="color: red;"} |

### T-GCN

| Lag | F | Classic | Proposed (L,L) | Proposed (4,L) |
|:---:|:---:|:---:|:---:|:---:|
| 8 | 8 | 0.1297<sub>±0.0011</sub> | [**0.1214**<sub>±0.0034</sub>]{style="color: red;"} | 0.1343<sub>±0.0371</sub> |
| 8 | 16 | 0.1295<sub>±0.0007</sub> | [**0.1245**<sub>±0.0074</sub>]{style="color: red;"} | 0.1273<sub>±0.0084</sub> |
| 8 | 24 | 0.1307<sub>±0.0008</sub> | [**0.1244**<sub>±0.0032</sub>]{style="color: red;"} | 0.1265<sub>±0.0068</sub> |
| 8 | 32 | 0.1314<sub>±0.0007</sub> | [**0.1250**<sub>±0.0061</sub>]{style="color: red;"} | 0.1300<sub>±0.0087</sub> |
| 12 | 8 | 0.1312<sub>±0.0010</sub> | [**0.1215**<sub>±0.0022</sub>]{style="color: red;"} | 0.1221<sub>±0.0037</sub> |
| 12 | 16 | 0.1319<sub>±0.0008</sub> | [**0.1217**<sub>±0.0016</sub>]{style="color: red;"} | 0.1252<sub>±0.0065</sub> |
| 12 | 24 | 0.1322<sub>±0.0006</sub> | [**0.1252**<sub>±0.0018</sub>]{style="color: red;"} | 0.1262<sub>±0.0059</sub> |
| 12 | 32 | 0.1328<sub>±0.0007</sub> | [**0.1256**<sub>±0.0026</sub>]{style="color: red;"} | 0.1261<sub>±0.0030</sub> |
| 24 | 8 | 0.1366<sub>±0.0016</sub> | 0.1506<sub>±0.0125</sub> | [**0.1308**<sub>±0.0037</sub>]{style="color: red;"} |
| 24 | 16 | 0.1388<sub>±0.0026</sub> | 0.1749<sub>±0.0193</sub> | [**0.1340**<sub>±0.0052</sub>]{style="color: red;"} |
| 24 | 24 | 0.1391<sub>±0.0013</sub> | 0.1732<sub>±0.0241</sub> | [**0.1379**<sub>±0.0040</sub>]{style="color: red;"} |
| 24 | 32 | 0.1402<sub>±0.0022</sub> | 0.1710<sub>±0.0182</sub> | [**0.1391**<sub>±0.0044</sub>]{style="color: red;"} |

### DCRNN

| Lag | F | Classic | Proposed (L,L) | Proposed (4,L) |
|:---:|:---:|:---:|:---:|:---:|
| 8 | 8 | 0.0577<sub>±0.0010</sub> | 0.0829<sub>±0.0484</sub> | [**0.0557**<sub>±0.0042</sub>]{style="color: red;"} |
| 8 | 16 | 0.0594<sub>±0.0015</sub> | 0.0667<sub>±0.0080</sub> | [**0.0540**<sub>±0.0020</sub>]{style="color: red;"} |
| 8 | 24 | 0.0603<sub>±0.0011</sub> | 0.0667<sub>±0.0097</sub> | [**0.0526**<sub>±0.0022</sub>]{style="color: red;"} |
| 8 | 32 | 0.0595<sub>±0.0007</sub> | 0.0655<sub>±0.0047</sub> | [**0.0529**<sub>±0.0014</sub>]{style="color: red;"} |
| 12 | 8 | 0.0583<sub>±0.0011</sub> | 0.1085<sub>±0.0604</sub> | [**0.0536**<sub>±0.0022</sub>]{style="color: red;"} |
| 12 | 16 | 0.0589<sub>±0.0007</sub> | 0.1267<sub>±0.0648</sub> | [**0.0535**<sub>±0.0010</sub>]{style="color: red;"} |
| 12 | 24 | 0.0606<sub>±0.0010</sub> | 0.0978<sub>±0.0435</sub> | [**0.0549**<sub>±0.0047</sub>]{style="color: red;"} |
| 12 | 32 | 0.0610<sub>±0.0011</sub> | 0.0971<sub>±0.0438</sub> | [**0.0551**<sub>±0.0034</sub>]{style="color: red;"} |
| 24 | 8 | 0.0815<sub>±0.0077</sub> | 0.1324<sub>±0.0262</sub> | [**0.0631**<sub>±0.0047</sub>]{style="color: red;"} |
| 24 | 16 | 0.0872<sub>±0.0055</sub> | 0.1403<sub>±0.0331</sub> | [**0.0669**<sub>±0.0048</sub>]{style="color: red;"} |
| 24 | 24 | 0.0847<sub>±0.0041</sub> | 0.1366<sub>±0.0346</sub> | [**0.0658**<sub>±0.0034</sub>]{style="color: red;"} |
| 24 | 32 | 0.0885<sub>±0.0032</sub> | 0.1357<sub>±0.0258</sub> | [**0.0656**<sub>±0.0052</sub>]{style="color: red;"} |

:::

## Typhoon Hinnamnor Period

**Typhoon Hinnamnor** (2022): Super typhoon that struck Korea on Sep 5-6, 2022. One of the strongest typhoons to affect Korea, causing significant damage to the southeastern region. ([Digital Typhoon](http://agora.ex.nii.ac.jp/digital-typhoon/summary/wnp/s/202211.html.en))

![Figure: Typhoon Hinnamnor period analysis. Top 9 regions with highest MSE reduction along the typhoon path.](figs/251121_top9_typhoon_map_timeseries_geojson.png){width="100%"}

## Regional Performance Improvement During Typhoon Period

<div style="width: fit-content; margin: auto;">

| # | Region | Classic | Proposed | MSE Reduction |
|:---:|:---|:---:|:---:|:---:|
| 1 | 경주 | 0.0791 | 0.0436 | **44.9%** |
| 2 | 함양 | 0.0596 | 0.0343 | **42.5%** |
| 3 | 창원 | 0.0644 | 0.0375 | **41.8%** |
| 4 | 의령 | 0.0561 | 0.0353 | **37.1%** |
| 5 | 부산 | 0.0753 | 0.0493 | **34.5%** |
| 6 | 고산 | 0.0388 | 0.0257 | **33.8%** |
| 7 | 양산 | 0.0746 | 0.0497 | **33.4%** |
| 8 | 김해 | 0.0725 | 0.0485 | **33.1%** |
| 9 | 청송 | 0.0539 | 0.0363 | **32.6%** |

</div>

→ **32-45% MSE reduction** along the typhoon path (southeastern Korean Peninsula)

# Discussions 

## Key Contributions

**1. Multiplicative Decomposition Framework**

- Introduced **$y = y^U \times y^P$ decomposition model** for solar irradiance
- **Resolved spurious correlation problem** caused by periodicity

**2. Asymmetric Component Modeling**

- **Independent graph structures and hyperparameters** tailored to each component
- Climate: lag=4, sparse / Periodic: lag=24, dense

**3. Robustness Under Extreme Weather**

- **32-45% MSE reduction** during Typhoon Hinnamnor period

## Future Work

- **External data integration**: satellite cloud imagery, numerical weather prediction, atmospheric reanalysis
- **Hybrid modeling**: replace $y^P$ with astronomical calculations, focus learning capacity on $y^U$

## Reviewer Question 1: Why Not Other Decomposition Methods?

> *"Comparison with alternative decomposition techniques such as STL, EMD, and Wavelet?"*

<div style="width: 70%; margin: auto;">

| Method | Decomposition Type | Result |
|:---:|:---:|:---|
| STL | Additive | Daily component remains in residual |
| EMD | Additive | Periodic component not isolated to specific IMF |
| Wavelet | Additive | Periodic energy dispersed across multiple levels |
| **EBT** | **Multiplicative** | **Clean two-component separation** |

</div>

→ **Additive methods fail to cleanly separate components. Only EBT achieves clean separation**

## Decomposition Comparison: Additive

![Figure: Additive decomposition comparison. EBT (top) vs STL, EMD, Wavelet.](figs/A1_fig1.png){width="100%"}

## Decomposition Comparison: Multiplicative

![Figure: Multiplicative decomposition comparison via log-transform. STL, EMD, Wavelet still fail to cleanly separate components.](figs/A1_fig2.png){width="100%"}

## Reviewer Question 2: What About Non-STGNN Deep Learning?

> *"Comparison with LSTM, CNN-LSTM, TCN, etc.?"*

**Baseline models**: TCN, LSTM, CNN-LSTM [@bai2018tcn; @hochreiter1997lstm; @agga2021short]

<div style="width: fit-content; margin: auto;">

| Model | MSE | Setting |
|:---:|:---:|:---:|
| TCN | 0.0601<sub>±.0012</sub> | L=24 |
| LSTM | 0.0841<sub>±.0023</sub> | L=8 |
| CNN-LSTM | 0.0975<sub>±.0037</sub> | L=8 |
| **Proposed (EBT+STGNN)** | [**0.0400**<sub>±.0003</sub>]{style="color: red;"} | L=8 |

</div>

→ **STGNN leveraging spatial information significantly outperforms temporal-only models** (33% improvement over TCN)

## Thank You

**Paper Information**

**"Spatio-Temporal Graph Neural Networks with Elastic-Band Transform for Solar Radiation Prediction"**

**Author**: Guebin Choi

*CMES-Computer Modeling in Engineering & Sciences*, 2025

**Contact**: guebin.choi@jbnu.ac.kr

## References
